\definecolor{hidden-draw}{RGB}{128, 128, 128}


\tikzstyle{my-box}=[
    rectangle,
    draw=hidden-draw,
    rounded corners,
    align=left,
    text opacity=1,
    minimum height=2.5em,
    minimum width=5em,
    inner sep=2pt,
    fill opacity=.8,
    line width=0.8pt,
]

\tikzstyle{leaf-head}=[my-box, minimum height=2.5em,
    draw=gray!80, 
    fill=gray!35,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]

\tikzstyle{leaf-task}=[my-box, minimum height=2.5em,
    draw=red!80, 
    fill=red!20,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]

\tikzstyle{leaf-paradigms}=[my-box, minimum height=2.5em,
    draw=orange!70, 
    fill=orange!15,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]
\tikzstyle{leaf-others}=[my-box, minimum height=2.5em,
    %fill=hidden-pink!80,
    draw=yellow!80, 
    fill=yellow!15,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]
\tikzstyle{leaf-other}=[my-box, minimum height=2.5em,
    %fill=hidden-pink!80,
    draw=green!80, 
    fill=green!15,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]
\tikzstyle{leaf-application}=[my-box, minimum height=2.5em,
    %fill=hidden-pink!80,
    draw=blue!80, 
    fill=blue!15,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]

\tikzstyle{modelnode-task}=[my-box, minimum height=2.5em,
    draw=red!80, 
    fill=red!20,  
    text=black, font=\normalsize,
    inner xsep=2pt,
    inner ysep=4pt,
    line width=0.8pt,
]
% KR-level-3
\tikzstyle{modelnode-paradigms}=[my-box, minimum height=2.5em,
    draw=orange!70, 
    fill=orange!15,  
    text=black, font=\normalsize,
    inner xsep=4pt,
    inner ysep=8pt,
    line width=1.5pt,
]
% ICI-level-3
\tikzstyle{modelnode-others}=[my-box, minimum height=2.5em,
    draw=yellow!80, 
    fill=yellow!15,  
    text=black, font=\normalsize,
    inner xsep=4pt,
    inner ysep=8pt,
    line width=1.5pt,
]
% LR-level-3
\tikzstyle{modelnode-other}=[my-box, minimum height=2.5em,
    draw=green!80, 
    fill=green!15,  
    text=black, font=\normalsize,
    inner xsep=4pt,
    inner ysep=8pt,
    line width=1.5pt,
]
% EP-level-3
\tikzstyle{modelnode-application}=[my-box, minimum height=2.5em,
    draw=blue!80, 
    fill=blue!15,  
    text=black, font=\normalsize,
    inner xsep=4pt,
    inner ysep=8pt,
    line width=1.5pt,
]

\begin{figure*}[!ht]
    \centering
    \resizebox{1\textwidth}{!}
    {
        \begin{forest}
            % forked edges,
            for tree={
                grow=east,
                reversed=true,
                anchor=base west,
                parent anchor=east,
                child anchor=west,
                base=left,
                font=\normalsize,
                rectangle,
                draw=hidden-draw,
                rounded corners,
                align=left,
                minimum width=1em,
                edge+={darkgray, line width=1pt},
                s sep=10pt,
                inner xsep=0pt,
                inner ysep=3pt,
                line width=0.8pt,
                ver/.style={rotate=90, child anchor=north, parent anchor=south, anchor=center},
            }, 
            % where level=1{text width=2em,font=\small,}{},
            % where level=2{text width=2em,font=\small,}{},
            % where level=3{text width=2em,font=\small,}{},
            [% 中括号之间不要换行！！！
                \textbf{Special Attention Heads},leaf-head, ver   
                [
                    \textbf{ \S \nameref{subsec:KR}}, leaf-paradigms, text width=15em
                    [
                        \ \textbf{General Tasks}, leaf-paradigms, text width=11em
                        [\textbf{ \toy{}Associative Memories}~\citep{AssociativeMemory_23_NIPS_Meta,MemoryMath_24_arXiv_MILES}{, }\textbf{\llama{}\pythia{}\gpt{}Memory Head}~\citep{KnowledgeConflict_24_arXiv_UCAS},  modelnode-paradigms, text width=39.5em]
                    ]
                    [
                       \ \textbf{Specific Tasks}, leaf-paradigms, text width=11em
                         [\textbf{ \gemma{}Constant Head}{ (MCQA)}~\citep{CorrectLetterHead_23_arXiv_DeepMind}{, }\textbf{\gemma{}Single Letter Head}{ (MCQA)}~\citep{CorrectLetterHead_23_arXiv_DeepMind}{, }\textbf{\gemma{}\mistral{}\llama{}\qwen{}\gpt{}Negative }\\\textbf{ Head (BDT)}~\citep{NegativeHead_24_arXiv_SNU},                          modelnode-paradigms, text width=39.5em]
                    ]
                ]
                [
                    \textbf{ \S \nameref{subsec:ICI}}, leaf-others,text width=15em
                    [
                        \ \textbf{Overall Structure}, leaf-others, text width=11.8em
                        [\textbf{ \pythia{}\gpt{}Previous Head}~\citep{InductionHeads_22_TCT_Anthropic,PreviousHead_23_AIForum_Google}{, }\textbf{\gpt{}Positional Head}~\citep{InformationFlow_24_arXiv_Meta,SpecialHead_19_ACL_Russia,PositionalHead_18_ACL_Helsinki}{, }\textbf{\toy{}Rare Words Head}~\citep{SpecialHead_19_ACL_Russia}{, } \textbf{\gpt{}Dup-}\\\textbf{ licate Head}~\citep{IOI_23_ICLR_Redwood}{, }\textbf{\yi{}\mistral{}\llama{}\qwen{}Retrieval head}~\citep{RetrievalHead_24_arXiv_PKU}{, }\textbf{\llama{}Global Retrieval head}~\citep{RetrievalHead_24_arXiv_Huawei}, modelnode-others, text width=38.7em]
                    ]
                    [
                         \ \textbf{Syntactic Information}, leaf-others, text width=11.8em
                         [\textbf{ \gpt{}Subword Merge Head}~\citep{InformationFlow_24_arXiv_Meta,SubwordHead_19_ACL_Portugal}{, }\textbf{\toy{}Syntactic Head}~\citep{SpecialHead_19_ACL_Russia,SyntacticHead_23_arXiv_NYU}{, }\textbf{\gpt{}Negative Name Mover}\\\textbf{ Head}~\citep{IOI_23_ICLR_Redwood}{, }\textbf{\llama{}\gpt{}Mover Head}~\citep{KnowledgeCircuit_24_arXiv_ZJU}{, }\textbf{\gpt{}Name Mover Head}~\citep{CopySupression_23_arXiv_Google}{, }\textbf{\gpt{}Backup Name Mover}\\\textbf{ Head}~\citep{CopySupression_23_arXiv_Google}{, }\textbf{\gpt{}Letter Mover Head}~\citep{AcronymPredict_24_arXiv_Alicante}, modelnode-others, text width=38.7em]
                    ]
                    [
                        \ \textbf{Semantic Information}, leaf-others, text width=11.8em
                        [\textbf{ \gpt{}Context Head}~\citep{KnowledgeConflict_24_arXiv_UCAS}{, }\textbf{\gemma{}Content Gatherer Head}~\citep{CorrectLetterHead_23_arXiv_DeepMind,ColorObject_24_ICLR_BrownU}{, }\textbf{\gpt{}Sentiment Summarizer}~\citep{Sentiment_23_arXiv_EleutherAI}{, }\\\textbf{ \internlm{}Semantic Induction Head}~\citep{Semantic_24_arXiv_SJTU}{, }\textbf{\pythia{}Subject Head}{ \& }\textbf{\llama{}\pythia{}\gpt{}Relation Head}~\citep{FactualRecall_24_arXiv_Independent,KnowledgeCircuit_24_arXiv_ZJU}, modelnode-others,text width=38.7em]
                    ]
                ]
                [
                    \textbf{ \S \nameref{subsec:LR}}, leaf-other,text width=15em
                    [
                        \ \textbf{In-context Learning}, leaf-other, text width=10.5em
                        [
                            \textbf{ \gpt{}Summary Reader}~\citep{Sentiment_23_arXiv_EleutherAI}{, }\textbf{\llama{}\gpt{}Function Vector}~\citep{FunctionVector_24_ICLR_NEU}{, }\textbf{\yi{}\mistral{}\llama{}\qwen{}\gpt{}Induction Head}~\citep{InductionHeads_22_TCT_Anthropic,Markov_24_arXiv_Harvard,FSL_24_ICML_UCL,HumanMemory_24_arXiv_UCSD,InductionHead_24_arXiv_UoA,InductionHead_24_ICLR_Princeton,InductionHead_24_ICML_MIT}, modelnode-other, text width=40em
                        ]
                    ]
                    [
                        \ \textbf{Effective Reasoning}, leaf-other, text width=10.5em
                        [
                            \textbf{ \llama{}Truthfulness Head}~\citep{ITI_23_NIPS_harvard,NL-ITI_24_arXiv-Samsung}{, }\textbf{\gemma{}\llama{}Accuracy Head}~\citep{CrossLingual_24_SIGIR_UCAS,LoFiT_24_arXiv_UT}{, }\textbf{\llama{}Consistency Head}~\citep{SemanticConsistency_24_ACL_TJU}{, }\textbf{\gpt{}Vul-}\\\textbf{ nerable Head}~\citep{VulnerableHead_24_arXiv_Alicante}, modelnode-other, text width=40em
                        ]
                    ]
                    [
                        \ \textbf{Task-Specific Reas.}, leaf-other, text width=10.5em
                        [
                            \textbf{ \gemma{}Correct Letter Head}{ (MCQA)}~\citep{CorrectLetterHead_23_arXiv_DeepMind}{, }\textbf{\toy{}Iteration Head}{ (Sequence)}~\citep{IterationHead_24_arXiv_Meta}{, }\textbf{\pythia{}\gpt{}\llama{}Successor}\\\textbf{ Head}{ (Ordinal)}~\citep{SuccessorHead_24_ICLR_Cambridge}{, }\textbf{\gpt{}Inhibition Head}{ (Term)}~\citep{IOI_23_ICLR_Redwood,HeadCooperation_24_arXiv_UoM}, modelnode-other, text width=40em
                        ]
                    ]
                ]
                [
                    \textbf{ \S \nameref{subsec:EP}}, leaf-application,text width=15em
                    [
                        \ \textbf{Information Aggregation}, leaf-application, text width=12.5em
                        [
                            \textbf{ \pythia{}Mixed Head}~\citep{FactualRecall_24_arXiv_Independent}, modelnode-application, text width=38em
                        ]
                    ]
                    [
                        \ \textbf{Signal Amplification}, leaf-application, text width=12.5em
                        [
                            \textbf{ \gemma{}Amplification Head}~\citep{CorrectLetterHead_23_arXiv_DeepMind}{, }\textbf{\llama{}Correct Head}~\citep{CorrectHead_24_arXiv_Allen}, modelnode-application, text width=38em
                        ]
                    ]
                    [
                        \ \textbf{Instruction Alignment}, leaf-application, text width=12.5em
                        [
                            \textbf{ \llama{}Coherence Head}~\citep{CrossLingual_24_SIGIR_UCAS}{, }\textbf{\llama{}\gpt{}Faithfulness Head}~\citep{FaithfulCoT_24_ICML_Harvard}, modelnode-application, text width=38em
                        ]
                    ]
                ]
            ]
        \end{forest}
    }
    \caption{\revise{Taxonomy of special attention heads in language models. The icons before each head indicate the specific LLM architectures where the head was discovered. \internlm{}: InternLM series. \yi{}: Yi series. \gemma{}: Gemma series. \mistral{}: Mistral series. \llama{}: Llama series. \qwen{}: Qwen series. \pythia{}: Pythia series. \gpt{}: GPT series. \toy{}: Toy models, such as two-layer decoder-only transformers.}}
    \label{fig:head_taxnomomy}
\vspace{-0.3cm}
\end{figure*}