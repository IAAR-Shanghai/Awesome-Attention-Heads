%%%%
% 探究技术&方法 (这里主要是一些基础方法，剩下的具体方法在AttnHead paper中)
%%%%
@article{ActivationPatching_22_NIPS_MIT,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}
@article{OldCircuit_20_distill_OpenAI,
  title={Zoom in: An introduction to circuits},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  volume={5},
  pages={e00024--001},
  year={2020}
}
@inproceedings{ActivationPatching_24_ICLR_Google,
    title={Towards Best Practices of Activation Patching in Language Models: Metrics and Methods},
    author={Fred Zhang and Neel Nanda},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    pages={1--28},
}
@article{ActivationPatching_24_arXiv_Google,
    title={How to use and interpret activation patching},
    author={Heimersheim, Stefan and Nanda, Neel},
    journal={Preprint at arXiv},
    year={2024},
    note={\href{https://doi.org/10.48550/arXiv.2404.15255}{https://doi.org/10.48550/arXiv.2404.15255}},
}
@article{ActivationAddition_23_arXiv_DeepMind,
    title={Activation addition: Steering language models without optimization},
    author={Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J and Mini, Ulisse and MacDiarmid, Monte},
    journal={Preprint at arXiv},
    year={2023},
    note={\href{https://doi.org/10.48550/arXiv.2308.10248}{https://doi.org/10.48550/arXiv.2308.10248}},
}
@inproceedings{SemanticConsistency_24_ACL_TJU,
    title = "Enhancing Semantic Consistency of Large Language Models through Model Editing: An Interpretability-Oriented Approach",
    author = "Yang, Jingyuan and Chen, Dapeng and Sun, Yajing and Li, Rongjun and Feng, Zhiyong and Peng, Wei",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "3343--3353",
}
@inproceedings{CausalAbstract_21_NIPS_Stanford,
    title = {Causal Abstractions of Neural Networks},
    author = {Geiger, Atticus and Lu, Hanson and Icard, Thomas and Potts, Christopher},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {9574--9586},
    publisher = {Curran Associates, Inc.},
    volume = {34},
    year = {2021}
}

@inproceedings{Greater_23_NIPS_UoA,
    author = {Hanna, Michael and Liu, Ollie and Variengien, Alexandre},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {76033--76060},
    publisher = {Curran Associates, Inc.},
    title = {How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model},
    volume = {36},
    year = {2023}
}
@inproceedings{ContextMix_23_EACL_Tilburg,
    title = "Quantifying Context Mixing in Transformers",
    author = "Mohebbi, Hosein and Zuidema, Willem and Chrupa{\l}a, Grzegorz and Alishahi, Afra",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    year = "2023",
    publisher = "Association for Computational Linguistics",
    pages = "3378--3400",
}
@inproceedings{DII_24_PMLR_Stanford,
    title={Finding alignments between interpretable causal variables and distributed neural representations},
    author={Geiger, Atticus and Wu, Zhengxuan and Potts, Christopher and Icard, Thomas and Goodman, Noah},
    booktitle={Causal Learning and Reasoning},
    pages={160--187},
    year={2024},
}
@inproceedings{ACDC_23_NIPS_UCL,
    author = {Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri\`{a}},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {16318--16352},
    publisher = {Curran Associates, Inc.},
    title = {Towards Automated Circuit Discovery for Mechanistic Interpretability},
    volume = {36},
    year = {2023}
}